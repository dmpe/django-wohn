{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home \u00b6 This project is high-level overview of Django-Wohn, aka Melive.xyz, project.","title":"Home"},{"location":"#home","text":"This project is high-level overview of Django-Wohn, aka Melive.xyz, project.","title":"Home"},{"location":"architecture/","text":"Development overtime \u00b6 Shows how CI/CD + architecture looked like in the past. CI/CD Pipeline \u00b6 Shows current deployment pipeline, from local changes to building a container on server. App's Class Diagramm \u00b6 Created using https://django-extensions.readthedocs.io/en/latest/graph_models.html and python3 manage.py graph_models -a -g -o arch/class_diagramm.png","title":"Development overtime"},{"location":"architecture/#development-overtime","text":"Shows how CI/CD + architecture looked like in the past.","title":"Development overtime"},{"location":"architecture/#cicd-pipeline","text":"Shows current deployment pipeline, from local changes to building a container on server.","title":"CI/CD Pipeline"},{"location":"architecture/#apps-class-diagramm","text":"Created using https://django-extensions.readthedocs.io/en/latest/graph_models.html and python3 manage.py graph_models -a -g -o arch/class_diagramm.png","title":"App's Class Diagramm"},{"location":"architecture/components/functions/","text":"Azure Functions \u00b6 We used Azure Functions to react or trigger events (functions) for some tasks, namely: Getting forex exchange data from (central) banks and storing them in the database. When creating real estate posting, user can send pictures via email (instead of uploading them). See GitHub issue for more ideas. Consumption plan should be enough. Though a premium plan which enables to use full docker images can be better due to large Python3 dependencies. Our Branch \u00b6 The branch with Azure functions: azure-functions , see link here . Build \u00b6 Sources: https://docs.microsoft.com/de-de/azure/azure-functions/functions-reference-python https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-function-linux-custom-image https://amaral.northwestern.edu/resources/guides/pyenv-tutorial 1. Pyenv \u00b6 Use pyenv in this worktree. Execute in the root: git switch azure-functions pyenv install 3 .6.9 # Azure is currently compatible only with Python 3.6 pyenv local 3 .6.9 2. Start Docker and Build Dockerfile \u00b6 sudo systemctl start docker func azure functionapp publish django-wohn --build-native-deps","title":"Azure Functions"},{"location":"architecture/components/functions/#azure-functions","text":"We used Azure Functions to react or trigger events (functions) for some tasks, namely: Getting forex exchange data from (central) banks and storing them in the database. When creating real estate posting, user can send pictures via email (instead of uploading them). See GitHub issue for more ideas. Consumption plan should be enough. Though a premium plan which enables to use full docker images can be better due to large Python3 dependencies.","title":"Azure Functions"},{"location":"architecture/components/functions/#our-branch","text":"The branch with Azure functions: azure-functions , see link here .","title":"Our Branch"},{"location":"architecture/components/functions/#build","text":"Sources: https://docs.microsoft.com/de-de/azure/azure-functions/functions-reference-python https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-function-linux-custom-image https://amaral.northwestern.edu/resources/guides/pyenv-tutorial","title":"Build"},{"location":"architecture/components/functions/#1-pyenv","text":"Use pyenv in this worktree. Execute in the root: git switch azure-functions pyenv install 3 .6.9 # Azure is currently compatible only with Python 3.6 pyenv local 3 .6.9","title":"1. Pyenv"},{"location":"architecture/components/functions/#2-start-docker-and-build-dockerfile","text":"sudo systemctl start docker func azure functionapp publish django-wohn --build-native-deps","title":"2. Start Docker and Build Dockerfile"},{"location":"development/container/","text":"Container \u00b6 Docker containers are currently used for building images and starting them with docker-compose. This project has been in \"migration state\" quite a lot of times and currently it represents most up-to-date architecture. Images are run on Azure cloud and therefore Melive.xyz also uses many of its services, for example: In use \u00b6 Azure Virtual Machines Azure KeyVault Azure Blob Storage Not used anymore \u00b6 Azure DNS Zone due to its limitations -> Moved to 3 rd Party Hosting Provider (OVH) 1. Prepare your VM \u00b6 On (close to any) cloud provider, create a VM and use cloud-init cloud-init commands to install required applications right during the initial setup. This should already include major components like Docker daemon. #include https://get.docker.com package_update: true package_upgrade: true packages: - git - curl - python3-pip runcmd: - curl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash - - apt install -y nodejs - curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add - - echo \"deb https://dl.yarnpkg.com/debian/ stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list - apt update - apt install -y yarn - [ sh, -c, 'sudo curl -L https://github.com/docker/compose/releases/download/$(curl -s https://api.github.com/repos/docker/compose/releases/latest | grep \"tag_name\" | cut -d \\\" -f4)/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose' ] - [ sh, -c, 'sudo chmod +x /usr/local/bin/docker-compose' ] final_message: \"The system is finally up, after $UPTIME seconds\" 2. New docker volume for each container \u00b6 Once installed, you need to have persistent volumes for images on a separate hard disk - in case your VM crashes, or you need to change VM's OS hard disk. The command below already assumes that a data disk has been mounted & properly setup in VM. docker volume create --driver local --opt type = none --opt device = /datadrive/_name_of_container --opt o = bind datadrive_name_of_container 3. Launch docker containers \u00b6 Clone this repo and cd' into it git clone https://github.com/dmpe/django-wohn . cd django-wohn git switch server-config git status Start docker-compose -f docker-compose.yaml up (-d)","title":"Container"},{"location":"development/container/#container","text":"Docker containers are currently used for building images and starting them with docker-compose. This project has been in \"migration state\" quite a lot of times and currently it represents most up-to-date architecture. Images are run on Azure cloud and therefore Melive.xyz also uses many of its services, for example:","title":"Container"},{"location":"development/container/#in-use","text":"Azure Virtual Machines Azure KeyVault Azure Blob Storage","title":"In use"},{"location":"development/container/#not-used-anymore","text":"Azure DNS Zone due to its limitations -> Moved to 3 rd Party Hosting Provider (OVH)","title":"Not used anymore"},{"location":"development/container/#1-prepare-your-vm","text":"On (close to any) cloud provider, create a VM and use cloud-init cloud-init commands to install required applications right during the initial setup. This should already include major components like Docker daemon. #include https://get.docker.com package_update: true package_upgrade: true packages: - git - curl - python3-pip runcmd: - curl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash - - apt install -y nodejs - curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add - - echo \"deb https://dl.yarnpkg.com/debian/ stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list - apt update - apt install -y yarn - [ sh, -c, 'sudo curl -L https://github.com/docker/compose/releases/download/$(curl -s https://api.github.com/repos/docker/compose/releases/latest | grep \"tag_name\" | cut -d \\\" -f4)/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose' ] - [ sh, -c, 'sudo chmod +x /usr/local/bin/docker-compose' ] final_message: \"The system is finally up, after $UPTIME seconds\"","title":"1. Prepare your VM"},{"location":"development/container/#2-new-docker-volume-for-each-container","text":"Once installed, you need to have persistent volumes for images on a separate hard disk - in case your VM crashes, or you need to change VM's OS hard disk. The command below already assumes that a data disk has been mounted & properly setup in VM. docker volume create --driver local --opt type = none --opt device = /datadrive/_name_of_container --opt o = bind datadrive_name_of_container","title":"2. New docker volume for each container"},{"location":"development/container/#3-launch-docker-containers","text":"Clone this repo and cd' into it git clone https://github.com/dmpe/django-wohn . cd django-wohn git switch server-config git status Start docker-compose -f docker-compose.yaml up (-d)","title":"3. Launch docker containers"},{"location":"development/heroku/","text":"Heroku \u00b6 Heroku requires several files to be in the root of the repository, see https://devcenter.heroku.com/articles/deploying-python Some of the necessary files can be found in the services/heroku/ folder of a dedicated branch. 1. Initial Setup steps \u00b6 If models have changed , following needs to be run first on a LOCAL PC : 1.1 Prepare PostgreSQL database \u00b6 sudo su postgres psql To create our DB, use psql : CREATE DATABASE b40re; CREATE USER jm WITH ENCRYPTED PASSWORD 'yourpass'; GRANT ALL PRIVILEGES ON DATABASE b40re TO jm; 1.2 Collect static files \u00b6 This also acts as a sort of test where you can spot some errors early on. It uploads static and media files directly to the Azure blob container too. python3 manage.py collectstatic 1.2.5 Create Django superuser \u00b6 In Heroku, via their cli: heroku run python3 manage.py createsuperuser --username admin --email ci@se.cz 1.3 Prepare migrations files \u00b6 If previously some deployments to the local PC were executed, then one has to clean & prepare database again. https://stackoverflow.com/a/40790734 Find and delete all migrations folders find -type d -name migrations -prune -exec rm -rf {} \\; Run makemigrations again https://stackoverflow.com/a/50309967 python3 manage.py makemigrations <model> Deploy to local/on remote server python3 manage.py migrate 1.4 Deploy to Heroku \u00b6 Heroku automatically runs collectstatic . git push master heroku 2. Common Heroku issues \u00b6 Kill heroku dyno heroku ps && heroku ps:stop web.1 3. Other notes \u00b6 When you add new css/js files to static folder, it is good idea to still run locally python3 manage.py collectstatic which will overwrite staticfiles folder & which again can be pushed to heroku (unless being ignored by gitignore ).","title":"Heroku"},{"location":"development/heroku/#heroku","text":"Heroku requires several files to be in the root of the repository, see https://devcenter.heroku.com/articles/deploying-python Some of the necessary files can be found in the services/heroku/ folder of a dedicated branch.","title":"Heroku"},{"location":"development/heroku/#1-initial-setup-steps","text":"If models have changed , following needs to be run first on a LOCAL PC :","title":"1. Initial Setup steps"},{"location":"development/heroku/#11-prepare-postgresql-database","text":"sudo su postgres psql To create our DB, use psql : CREATE DATABASE b40re; CREATE USER jm WITH ENCRYPTED PASSWORD 'yourpass'; GRANT ALL PRIVILEGES ON DATABASE b40re TO jm;","title":"1.1 Prepare PostgreSQL database"},{"location":"development/heroku/#12-collect-static-files","text":"This also acts as a sort of test where you can spot some errors early on. It uploads static and media files directly to the Azure blob container too. python3 manage.py collectstatic","title":"1.2 Collect static files"},{"location":"development/heroku/#125-create-django-superuser","text":"In Heroku, via their cli: heroku run python3 manage.py createsuperuser --username admin --email ci@se.cz","title":"1.2.5 Create Django superuser"},{"location":"development/heroku/#13-prepare-migrations-files","text":"If previously some deployments to the local PC were executed, then one has to clean & prepare database again. https://stackoverflow.com/a/40790734 Find and delete all migrations folders find -type d -name migrations -prune -exec rm -rf {} \\; Run makemigrations again https://stackoverflow.com/a/50309967 python3 manage.py makemigrations <model> Deploy to local/on remote server python3 manage.py migrate","title":"1.3 Prepare migrations files"},{"location":"development/heroku/#14-deploy-to-heroku","text":"Heroku automatically runs collectstatic . git push master heroku","title":"1.4 Deploy to Heroku"},{"location":"development/heroku/#2-common-heroku-issues","text":"Kill heroku dyno heroku ps && heroku ps:stop web.1","title":"2. Common Heroku issues"},{"location":"development/heroku/#3-other-notes","text":"When you add new css/js files to static folder, it is good idea to still run locally python3 manage.py collectstatic which will overwrite staticfiles folder & which again can be pushed to heroku (unless being ignored by gitignore ).","title":"3. Other notes"},{"location":"development/own_server/","text":"Own Server \u00b6 Before I have switched to container based, CI/CD workflow, I have installed everything needed on my server myself... Some important components are located in services/own_server . See heroku page as well. To install pgadmin4, follow https://www.pgadmin.org/docs/pgadmin4/4.x/server_deployment.html guideline. 1. Deploy to own server \u00b6 Create Django superuser \u00b6 python3 manage.py createsuperuser --username admin --email ci@se.cz Then, execute on remote server following commands whenever Django model(s) change. python3 manage.py makemigrations <model> && python3 manage.py migrate && sudo systemctl restart gunicorn.service After git commit & push to the server, you can also use a special post-receive hook https://gist.github.com/lemiorhan/8912188 . Setup Git Repo with post-receive hook \u00b6 At certain point of time, the goal was to use AWS Cloud9 IDE to edit and push -- on the same server (username@domain:/home/username/domain_push.git) -- to the git repository, from which website was \"deployment\" (aka gunicorn restarted). Today, this is totally obsolete with VS Code (remote development or Eclipse Che) for instance. See this guide https://stackoverflow.com/a/40479963 E.g. for AWS Cloud9 IDE, first clone git repo somewhere Then create a new bare repo which is used for pushing to it and now you have to add/register aforementioned post-recieve hook. 2. Some common issues \u00b6 Start Django manually python3 manage.py runserver --nostatic Adding new SSL certificates via certbot (letsencrypt) sudo certbot --nginx certonly Nginx 502 gateway issue after VM reboot Just restart nginx, then sudo systemctl restart gunicorn.service as well as stop that socket thing 3. Run Celery and RabbitMQ Management UI \u00b6 (This could have been moved to Azure Functions for example.) Source: https://stackoverflow.com/a/12900126/2171456 First install RabbitMQ (message broker), then Celery (\"worker\"). sudo rabbitmq-plugins enable rabbitmq_management sudo rabbitmqctl add_user jm password sudo rabbitmqctl set_user_tags jm administrator Run Celery from b40re directory using: sudo systemctl restart rabbitmq<TAB> celery -A vanoce worker -l info Then, in an another bash window, execute commands below so that tasks such as fetching forex/currency data are run immediately. python3 manage.py shell from userMng.third_party_services.celery_tasks import parse_forex_data rst = parse_forex_data.apply ()","title":"Own Server"},{"location":"development/own_server/#own-server","text":"Before I have switched to container based, CI/CD workflow, I have installed everything needed on my server myself... Some important components are located in services/own_server . See heroku page as well. To install pgadmin4, follow https://www.pgadmin.org/docs/pgadmin4/4.x/server_deployment.html guideline.","title":"Own Server"},{"location":"development/own_server/#1-deploy-to-own-server","text":"","title":"1. Deploy to own server"},{"location":"development/own_server/#create-django-superuser","text":"python3 manage.py createsuperuser --username admin --email ci@se.cz Then, execute on remote server following commands whenever Django model(s) change. python3 manage.py makemigrations <model> && python3 manage.py migrate && sudo systemctl restart gunicorn.service After git commit & push to the server, you can also use a special post-receive hook https://gist.github.com/lemiorhan/8912188 .","title":"Create Django superuser"},{"location":"development/own_server/#setup-git-repo-with-post-receive-hook","text":"At certain point of time, the goal was to use AWS Cloud9 IDE to edit and push -- on the same server (username@domain:/home/username/domain_push.git) -- to the git repository, from which website was \"deployment\" (aka gunicorn restarted). Today, this is totally obsolete with VS Code (remote development or Eclipse Che) for instance. See this guide https://stackoverflow.com/a/40479963 E.g. for AWS Cloud9 IDE, first clone git repo somewhere Then create a new bare repo which is used for pushing to it and now you have to add/register aforementioned post-recieve hook.","title":"Setup Git Repo with post-receive hook"},{"location":"development/own_server/#2-some-common-issues","text":"Start Django manually python3 manage.py runserver --nostatic Adding new SSL certificates via certbot (letsencrypt) sudo certbot --nginx certonly Nginx 502 gateway issue after VM reboot Just restart nginx, then sudo systemctl restart gunicorn.service as well as stop that socket thing","title":"2. Some common issues"},{"location":"development/own_server/#3-run-celery-and-rabbitmq-management-ui","text":"(This could have been moved to Azure Functions for example.) Source: https://stackoverflow.com/a/12900126/2171456 First install RabbitMQ (message broker), then Celery (\"worker\"). sudo rabbitmq-plugins enable rabbitmq_management sudo rabbitmqctl add_user jm password sudo rabbitmqctl set_user_tags jm administrator Run Celery from b40re directory using: sudo systemctl restart rabbitmq<TAB> celery -A vanoce worker -l info Then, in an another bash window, execute commands below so that tasks such as fetching forex/currency data are run immediately. python3 manage.py shell from userMng.third_party_services.celery_tasks import parse_forex_data rst = parse_forex_data.apply ()","title":"3. Run Celery and RabbitMQ Management UI"}]}