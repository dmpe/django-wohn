{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home \u00b6 This project is high-level overview of Django-Wohn, aka Melive.xyz, project.","title":"Home"},{"location":"#home","text":"This project is high-level overview of Django-Wohn, aka Melive.xyz, project.","title":"Home"},{"location":"architecture/","text":"Development overtime \u00b6 Shows how CI/CD + architecture looked like in the past. CI/CD Pipeline \u00b6 Shows current deployment pipeline, from local changes to building a container on server. App's Class Diagramm \u00b6 Created using https://django-extensions.readthedocs.io/en/latest/graph_models.html and python3 manage.py graph_models -a -g -o arch/class_diagramm.png","title":"Index"},{"location":"architecture/#development-overtime","text":"Shows how CI/CD + architecture looked like in the past.","title":"Development overtime"},{"location":"architecture/#cicd-pipeline","text":"Shows current deployment pipeline, from local changes to building a container on server.","title":"CI/CD Pipeline"},{"location":"architecture/#apps-class-diagramm","text":"Created using https://django-extensions.readthedocs.io/en/latest/graph_models.html and python3 manage.py graph_models -a -g -o arch/class_diagramm.png","title":"App's Class Diagramm"},{"location":"development/container/","text":"Docker containers are currently used for building images and starting them with docker-compose. This project has been in migration state quite a lot of times. Currently, it is run on Azure Cloud and therefore uses many of its services, for example: In use \u00b6 Azure Virtual Machines Azure KeyVault Azure Blob Storage Not used anymore \u00b6 Azure DNS Zone due to its limitations -> Moved to 3 rd Party Hosting Provider (OVH) 1. Prepare your VM \u00b6 On (close to any) cloud provider, create VM and use cloud-init cloud-init statements to install required applications right during the initial VM setup. #include https://get.docker.com package_update: true package_upgrade: true packages: - git - curl - python3-pip runcmd: - curl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash - - apt install -y nodejs - curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add - - echo \"deb https://dl.yarnpkg.com/debian/ stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list - apt update - apt install -y yarn - [sh, -c, 'sudo curl -L https://github.com/docker/compose/releases/download/$(curl -s https://api.github.com/repos/docker/compose/releases/latest | grep \"tag_name\" | cut -d \\\" -f4)/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose'] - [sh, -c, 'sudo chmod +x /usr/local/bin/docker-compose'] final_message: \"The system is finally up, after $UPTIME seconds\" as installing Docker daemon is a major component on the VM. 2. New docker volume for each container \u00b6 You want to have a persistent docker volume on a separate hard disk - in case your VM crashes, or you need to change it with its OS hard disk. This command already assumes that a data disk has already been mounted into VM. docker volume create --driver local --opt type=none --opt device=/datadrive/_name_of_container --opt o=bind datadrive_name_of_container 3. Launch docker containers \u00b6 Clone this repo and cd' into it git clone https://github.com/dmpe/django-wohn . cd django-wohn git switch server-config git status Start docker-compose -f docker-compose.yaml up (-d)","title":"Container"},{"location":"development/container/#in-use","text":"Azure Virtual Machines Azure KeyVault Azure Blob Storage","title":"In use"},{"location":"development/container/#not-used-anymore","text":"Azure DNS Zone due to its limitations -> Moved to 3 rd Party Hosting Provider (OVH)","title":"Not used anymore"},{"location":"development/container/#1-prepare-your-vm","text":"On (close to any) cloud provider, create VM and use cloud-init cloud-init statements to install required applications right during the initial VM setup. #include https://get.docker.com package_update: true package_upgrade: true packages: - git - curl - python3-pip runcmd: - curl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash - - apt install -y nodejs - curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add - - echo \"deb https://dl.yarnpkg.com/debian/ stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list - apt update - apt install -y yarn - [sh, -c, 'sudo curl -L https://github.com/docker/compose/releases/download/$(curl -s https://api.github.com/repos/docker/compose/releases/latest | grep \"tag_name\" | cut -d \\\" -f4)/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose'] - [sh, -c, 'sudo chmod +x /usr/local/bin/docker-compose'] final_message: \"The system is finally up, after $UPTIME seconds\" as installing Docker daemon is a major component on the VM.","title":"1. Prepare your VM"},{"location":"development/container/#2-new-docker-volume-for-each-container","text":"You want to have a persistent docker volume on a separate hard disk - in case your VM crashes, or you need to change it with its OS hard disk. This command already assumes that a data disk has already been mounted into VM. docker volume create --driver local --opt type=none --opt device=/datadrive/_name_of_container --opt o=bind datadrive_name_of_container","title":"2. New docker volume for each container"},{"location":"development/container/#3-launch-docker-containers","text":"Clone this repo and cd' into it git clone https://github.com/dmpe/django-wohn . cd django-wohn git switch server-config git status Start docker-compose -f docker-compose.yaml up (-d)","title":"3. Launch docker containers"},{"location":"development/heroku/","text":"Heroku requires several files to be in the root of the repository, see https://devcenter.heroku.com/articles/deploying-python Some of the necessary files can be found in the services/heroku/ folder of a dedicated branch. 1. Common tasks for local and Heroku \u00b6 If models have been changed , following needs to be run on a LOCAL PC : 1.1 Clean PostgreSQL database \u00b6 If previously some deployments to the local PC have been executed, then one has to clean & prepare database again. sudo su postgres psql To create DB via psql , use CREATE DATABASE b40re; CREATE USER jm WITH ENCRYPTED PASSWORD 'yourpass'; GRANT ALL PRIVILEGES ON DATABASE b40re TO jm; 1.2 Collect static files \u00b6 This also acts as a sort of test where you can spot some errors early on. It also uploads static and media files directly to the Azure blob container. python3 manage.py collectstatic 1.2.5 Create DJango superuser \u00b6 Via their cli heroku run python3 manage.py createsuperuser --username admin --email ci@se.cz 1.3 Prepare migrations files \u00b6 https://stackoverflow.com/a/40790734 Find and delete all migrations folders find -type d -name migrations -prune -exec rm -rf {} \\; Run makemigrations again https://stackoverflow.com/a/50309967 python3 manage.py makemigrations core && python3 manage.py makemigrations userMng Deploy to local/on remote server python3 manage.py migrate 1.4 Deploy to Heroku \u00b6 Heroku automatically runs collectstatic. git push master heroku 2. Common issues \u00b6 Kill heroku dyno heroku ps && heroku ps:stop web.1 3. Other notes \u00b6 When you add new css/js to static folder, it is good idea to still run locally python3 manage.py collectstatic which will overwrite staticfiles & which again can be pushed to heroku (unless being ignored by gitignore ).","title":"Heroku"},{"location":"development/heroku/#1-common-tasks-for-local-and-heroku","text":"If models have been changed , following needs to be run on a LOCAL PC :","title":"1. Common tasks for local and Heroku"},{"location":"development/heroku/#11-clean-postgresql-database","text":"If previously some deployments to the local PC have been executed, then one has to clean & prepare database again. sudo su postgres psql To create DB via psql , use CREATE DATABASE b40re; CREATE USER jm WITH ENCRYPTED PASSWORD 'yourpass'; GRANT ALL PRIVILEGES ON DATABASE b40re TO jm;","title":"1.1 Clean PostgreSQL database"},{"location":"development/heroku/#12-collect-static-files","text":"This also acts as a sort of test where you can spot some errors early on. It also uploads static and media files directly to the Azure blob container. python3 manage.py collectstatic","title":"1.2 Collect static files"},{"location":"development/heroku/#125-create-django-superuser","text":"Via their cli heroku run python3 manage.py createsuperuser --username admin --email ci@se.cz","title":"1.2.5 Create DJango superuser"},{"location":"development/heroku/#13-prepare-migrations-files","text":"https://stackoverflow.com/a/40790734 Find and delete all migrations folders find -type d -name migrations -prune -exec rm -rf {} \\; Run makemigrations again https://stackoverflow.com/a/50309967 python3 manage.py makemigrations core && python3 manage.py makemigrations userMng Deploy to local/on remote server python3 manage.py migrate","title":"1.3 Prepare migrations files"},{"location":"development/heroku/#14-deploy-to-heroku","text":"Heroku automatically runs collectstatic. git push master heroku","title":"1.4 Deploy to Heroku"},{"location":"development/heroku/#2-common-issues","text":"Kill heroku dyno heroku ps && heroku ps:stop web.1","title":"2. Common issues"},{"location":"development/heroku/#3-other-notes","text":"When you add new css/js to static folder, it is good idea to still run locally python3 manage.py collectstatic which will overwrite staticfiles & which again can be pushed to heroku (unless being ignored by gitignore ).","title":"3. Other notes"},{"location":"development/own_server/","text":"Before I have switched to container based CI/CD, I have installed everything on server myself... Some important components are located in services/own_server . See heroku page as well. To install pgadmin4, follow https://www.pgadmin.org/docs/pgadmin4/4.x/server_deployment.html 1. Deploy to own server \u00b6 Create superuser \u00b6 python3 manage.py createsuperuser --username admin --email ci@se.cz Then, execute on remote server following commands whenever models change. python3 manage.py makemigrations core && python3 manage.py makemigrations userMng && python3 manage.py migrate && sudo systemctl restart gunicorn.service After pushing a commit to the server, see a special post-receive hook https://gist.github.com/lemiorhan/8912188 too. Setup Git Repo with post-receive hook \u00b6 The goal was to use AWS Cloud9 IDE to push -- on the same server (username@domain:/home/username/domain_push.git) -- to the git repository which acts as deployment repo. Today, this is totally obsolete which VS Code (remote development or Eclipse Che) for instance. See this guide https://stackoverflow.com/a/40479963 E.g. for AWS Cloud9 IDE, first clone this repo somewhere Create a new bare repo which is used for pushing and in it, add/register aforementioned post-recieve hook. 2. Common issues \u00b6 Start Django manually python3 manage.py runserver --nostatic Adding new SSL certificates via certbot (letsencrypt) sudo certbot --nginx certonly Nginx 502 gateway issue after VM reboot Just restart nginx, then sudo systemctl restart gunicorn.service as well as stop that socket thing 3. Run Celery and RabbitMQ Management UI \u00b6 // TODO: Could be moved to Azure Functions First install RabbitMQ , then Celery . sudo rabbitmq-plugins enable rabbitmq_management sudo rabbitmqctl add_user jm password sudo rabbitmqctl set_user_tags jm administrator Run Celery from b40re directory using sudo systemctl restart rabbitmq<TAB> celery -A vanoce worker -l info Then, in an another bash window, execute commands below so that tasks such as fetching forex/currency data are run immediately. python3 manage.py shell from userMng.third_party_services.celery_tasks import parse_forex_data rst = parse_forex_data.apply() Source: https://stackoverflow.com/a/12900126/2171456","title":"Own server"},{"location":"development/own_server/#1-deploy-to-own-server","text":"","title":"1. Deploy to own server"},{"location":"development/own_server/#create-superuser","text":"python3 manage.py createsuperuser --username admin --email ci@se.cz Then, execute on remote server following commands whenever models change. python3 manage.py makemigrations core && python3 manage.py makemigrations userMng && python3 manage.py migrate && sudo systemctl restart gunicorn.service After pushing a commit to the server, see a special post-receive hook https://gist.github.com/lemiorhan/8912188 too.","title":"Create superuser"},{"location":"development/own_server/#setup-git-repo-with-post-receive-hook","text":"The goal was to use AWS Cloud9 IDE to push -- on the same server (username@domain:/home/username/domain_push.git) -- to the git repository which acts as deployment repo. Today, this is totally obsolete which VS Code (remote development or Eclipse Che) for instance. See this guide https://stackoverflow.com/a/40479963 E.g. for AWS Cloud9 IDE, first clone this repo somewhere Create a new bare repo which is used for pushing and in it, add/register aforementioned post-recieve hook.","title":"Setup Git Repo with post-receive hook"},{"location":"development/own_server/#2-common-issues","text":"Start Django manually python3 manage.py runserver --nostatic Adding new SSL certificates via certbot (letsencrypt) sudo certbot --nginx certonly Nginx 502 gateway issue after VM reboot Just restart nginx, then sudo systemctl restart gunicorn.service as well as stop that socket thing","title":"2. Common issues"},{"location":"development/own_server/#3-run-celery-and-rabbitmq-management-ui","text":"// TODO: Could be moved to Azure Functions First install RabbitMQ , then Celery . sudo rabbitmq-plugins enable rabbitmq_management sudo rabbitmqctl add_user jm password sudo rabbitmqctl set_user_tags jm administrator Run Celery from b40re directory using sudo systemctl restart rabbitmq<TAB> celery -A vanoce worker -l info Then, in an another bash window, execute commands below so that tasks such as fetching forex/currency data are run immediately. python3 manage.py shell from userMng.third_party_services.celery_tasks import parse_forex_data rst = parse_forex_data.apply() Source: https://stackoverflow.com/a/12900126/2171456","title":"3. Run Celery and RabbitMQ Management UI"}]}